{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "263ffcf7",
   "metadata": {},
   "source": [
    "# GRIP The Sparks Foundation\n",
    "# Computer vision & IoT\n",
    "## Task 3 : Social Distancing Detector\n",
    "## Name : Padmasandhiya P"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a3f228a",
   "metadata": {},
   "source": [
    "#### Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3c696f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import imutils\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b4b419",
   "metadata": {},
   "source": [
    "#### Defining function to calculate distance between two people"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a141ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(indexes):\n",
    "\n",
    "    centres = []\n",
    "    colors = {}\n",
    "    dict = {}\n",
    "    Safe_Distance = 120\n",
    "\n",
    "    for i in indexes.flatten():\n",
    "        x, y, w, h = boxes[i]\n",
    "        x_mid = int(x+w/2)\n",
    "        y_mid = int(y+h/2)\n",
    "        dict[i] = 0\n",
    "        centres.append([i,x_mid,y_mid])\n",
    "\n",
    "    for i in range(len(indexes)-1):\n",
    "        for j in range(i+1,len(indexes)):\n",
    "            dist = distance.euclidean(centres[i][1:3],centres[j][1:3])\n",
    "\n",
    "            if dist<Safe_Distance:\n",
    "                dict[centres[i][0]]=1\n",
    "                dict[centres[j][0]]=1\n",
    "    risky=0\n",
    "    for i,val in dict.items():\n",
    "        if val==0:\n",
    "            colors[i] = (0,255,0)\n",
    "\n",
    "        else:\n",
    "            colors[i] = (0,0,255)\n",
    "            risky+=1\n",
    "\n",
    "    return colors,risky"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c30fda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we would be using yolov3 to detect person in the images \n",
    "\n",
    "net = cv.dnn.readNet('yolov3.weights','yolov3.cfg')\n",
    "classes = []\n",
    "\n",
    "with open('coco.names','r') as f:\n",
    "    classes = f.read().split(\"\\n\")\n",
    "\n",
    "cap = cv.VideoCapture(\"street.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82427b70",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\NANDIT~1\\AppData\\Local\\Temp/ipykernel_17400/915279457.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mdetection\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                 \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetection\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m                 \u001b[0mclass_id\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m                 \u001b[0mconfidence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1191\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1192\u001b[0m     \"\"\"\n\u001b[1;32m-> 1193\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmax'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1194\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    frame,img = cap.read()\n",
    "\n",
    "    if frame:\n",
    "\n",
    "        img = imutils.resize(img, width=1280,height=1000)\n",
    "        height,width,_ = img.shape\n",
    "\n",
    "        blob = cv.dnn.blobFromImage(img,1/255,(416,416),(0,0,0),swapRB=True,crop=False)\n",
    "\n",
    "        net.setInput(blob)\n",
    "\n",
    "        output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "        layerOutputs = net.forward(output_layers_names)\n",
    "\n",
    "        boxes = []\n",
    "        confidences = []\n",
    "        class_ids = []\n",
    "\n",
    "        for output in layerOutputs:\n",
    "            for detection in output:\n",
    "                scores = detection[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "\n",
    "                if confidence > 0.5 and class_id == 0:\n",
    "                    center_x = int(detection[0]*width)\n",
    "                    center_y = int(detection[1]*height)\n",
    "                    w = int(detection[2]*width)\n",
    "                    h = int(detection[3]*height)\n",
    "\n",
    "                    x = int(center_x-w/2)\n",
    "                    y = int(center_y-h/2)\n",
    "\n",
    "                    boxes.append([x,y,w,h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "\n",
    "        indexes = cv.dnn.NMSBoxes(boxes,confidences,0.5,0.4)\n",
    "\n",
    "        font = cv.FONT_HERSHEY_PLAIN\n",
    "\n",
    "        color = (0,255,0)\n",
    "        risky=0\n",
    "\n",
    "        if(len(indexes)>1):\n",
    "            colors,risky = calculate_distance(indexes)\n",
    "\n",
    "        if len(indexes)>0:\n",
    "\n",
    "            for i in indexes.flatten():\n",
    "                x,y,w,h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "\n",
    "                if len(indexes)>1:\n",
    "                    color = colors[i]\n",
    "\n",
    "                if color==(0,255,0):\n",
    "                    label='SAFE'\n",
    "                    k=55\n",
    "\n",
    "                else:\n",
    "                    label=\"RISK\"\n",
    "                    k=62\n",
    "\n",
    "                if(risky>0):\n",
    "                    cv.rectangle(img, (0, 0), (462, 30), (255, 255, 255), -1)\n",
    "                    cv.putText(img,\"NO OF SOCIAL DISTANCE VIOLATIONS :\"+f\"{risky}\",(10,20),font,1.4,(0,0,255),2)\n",
    "                else:\n",
    "                    cv.rectangle(img, (0, 0), (150, 30), (255, 255, 255), -1)\n",
    "                    cv.putText(img, \"  SAFE  \", (15, 20), font, 1.4, (0,255,0), 2)\n",
    "\n",
    "                cv.rectangle(img,(x,y),(x+w,y+h),color,2)\n",
    "                cv.rectangle(img,(x,y-5),(x+k,y+15),(255,255,255),-1)\n",
    "                cv.putText(img,label,(x+5,y+10),font,1.3,color,2)\n",
    "        \n",
    "        cv.imshow('img',img)\n",
    "        key = cv.waitKey(1)\n",
    "\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec526356",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3dbb8eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
